<html>
<head>
    <style>
        body {
            font-family: Baskerville, Baskerville Old Face, Garamond, Times New Roman, serif;
            font-style: normal;
            font-weight: 400;
        }
        h1 {
            font-size: 24px;
        }
        h2 {
            font-size: 20px;
            margin-top: 40px;
        }

        h3 {
            font-size: 18px;
            margin-top: 32px;
        }
        p, div {
            font-size: 16px;
        }
        pre {
            font-family: monospace;
            font-size: 12px;
        }
        tr.border_bottom td {
            border-bottom:1pt solid black;
        }
        tr.border_top td {
            border-top:1pt solid black;
        }
    </style>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Online-Trained Upsampler for Deep Low Complexity Video Compression</title>
</head>
<body>
<div style="text-align: center">
    <h1>Online-Trained Upsampler for Deep Low Complexity Video Compression</h1>
    <h2>A conditional <a href="https://neuralfields.cs.brown.edu/index.html">Neural Field</a> for Compressed Video Upsampling</h2>
    <h3><a href="https://openaccess.thecvf.com/content/ICCV2021/html/Klopp_Online-Trained_Upsampler_for_Deep_Low_Complexity_Video_Compression_ICCV_2021_paper.html">ICCV 2021</a></h3>
    <p><a href="mailto:kloppjp@gmail.com">Jan P. Klopp</a>*, Keng-Chi Liu<sup>&#xa7;</sup>, Shao-Yi Chien*, Liang-Gee Chen*</p>
    <p style="font-size: 14px">*Graduate Institute of Electrical Engineering, National Taiwan University</p>
    <p style="font-size: 14px"><sup>&#xa7;</sup>Taiwan AI Labs</p>
    <h2>Main Results</h2>
    <div style="width: 700px; margin-left: auto; margin-right: auto; text-align: justify;  line-height: 160%">
        <ul>
            <li>Online (at encoding time) trained upsampler applied after conventional compression</li>
            <li>Highly efficient compared to other deep learning based coding solutions (< 1 KMAC/pix for decoder)</li>
            <li>Coding gains (BDRate) up to 27.5% over x265, outperforming <a href="https://kloppjp.github.io/cnnvc/">Online-Trained Denoiser</a></li>
            <li>Applicable to both low delay and random access coding modes</li>
        </ul>
    </div>
    <h2>Methods</h2>
    <h3>System</h3>
    <img src="overview.png" style="width: 700px">
    <div style="width: 700px; margin-left: auto; margin-right: auto; text-align: justify; line-height: 140%">
        The upsampler is trained on a group of pictures on the low-resolution output of the conventional encoder. 
        Its parameters are signalled alongside the conventional encoder's code.
    </div>
    <h3>Network</h3>
    <img src="network.png" style="width: 700px">
    <div style="width: 700px; margin-left: auto; margin-right: auto; text-align: justify; line-height: 140%">
        The chosen network structure integrates positional information, internal features of the codec (motion vectors, block information), 
        and the decoded signal to predict the upsampling residual. The network architecture is simple enough to allow for fast training 
        when encoding and low complexity inference at decoding time.
    </div>
    <h3>Zero Latency Processing</h3>
    <img src="zero_lat.png" alt="Zero latency parameter training and transmission process." style="width: 400px">
    <div style="width: 700px; margin-left: auto; margin-right: auto; text-align: justify; line-height: 140%">
    Zero latency processing is enabled by reusing a previously signaled set of parameters at the decoder side while the encoder is updating
    the parameters using group of frames currently being encoded.
    </div>
    <h3>Scope</h3>
    <img src="scope.png" alt="Scope of the proposed work." style="width: 300px">
    <div style="width: 700px; margin-left: auto; margin-right: auto; text-align: justify; line-height: 140%">
    Compression is about finding redundancies in data. Our work specifically targets redundancies that span dozens or even hundred frames. 
    Note that this differs from motion compensation or other flow-based methods as our method can deal with textures that have a coherent 
    structure but are difficult to predicut such as particle systems (fire, smoke, water) or a large group of leaves moving randomly in the wind.
    </div>
    <h2>Material</h2>
    <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Klopp_Online-Trained_Upsampler_for_Deep_Low_Complexity_Video_Compression_ICCV_2021_paper.pdf">Paper (CVF)</a>&nbsp;&nbsp;&nbsp;
    <h2>Cite</h2>
    <p>If you find our work helpful for your research, please consider citing it:</p>
    <div style="width: 700px; margin-left: auto; margin-right: auto; text-align: justify; font-size: 14px">
        <pre>@InProceedings{Klopp_2021_ICCV,
            author    = {Klopp, Jan P. and Liu, Keng-Chi and Chien, Shao-Yi and Chen, Liang-Gee},
            title     = {Online-Trained Upsampler for Deep Low Complexity Video Compression},
            booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
            month     = {October},
            year      = {2021},
            pages     = {7929-7938}
        }</pre>
    </div>
    <div style="display: inline-block; margin-left: auto; margin-right: auto; text-align: justify; font-size: 14px; margin-top: 20px">
        <a href="https://www.ntu.edu.tw/" ><img src="ntu_logo.png" style="width: auto; height: 60px; display: inline-block; margin-left: 20px; margin-right: 20px;" alt="Logo of National Taiwan University"></a>
    </div>

</div>

</body>
</html>
